{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from config import *\n",
    "from test_bad_word import *\n",
    "from utility import *\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pd.options.display.max_columns = None\n",
    "#pd.options.display.mpl_style = 'default'\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import raw data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df_train = pd.read_csv(DATA_DIR + '/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_train['length']=df_train['Comment'].map(lambda x:len(x.split()))\n",
    "#df_train = df_train[df_train['length']<300]\n",
    "df_test = pd.read_csv(DATA_DIR + '/test_with_solutions.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "num_test = df_test.shape[0]\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_1 = pd.read_csv(DATA_DIR + '/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_train_2 = pd.read_csv(DATA_DIR + '/test_with_solutions.csv', encoding=\"ISO-8859-1\")\n",
    "df_train = pd.concat((df_train_1, df_train_2), axis=0, ignore_index=True)\n",
    "df_train['length']=df_train['Comment'].map(lambda x:len(x.split()))\n",
    "#df_train = df_train[df_train['length']<300]\n",
    "df_test = pd.read_csv(DATA_DIR + '/impermium_verification_labels.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "num_test = df_test.shape[0]\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['Comment']=df_all['Comment'].map(lambda x:parser(x))\n",
    "df_all['Comment']=df_all['Comment'].map(lambda x:badword_replacer(x))\n",
    "df_all['Comment_stemmed']=df_all['Comment'].map(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "\n",
    "df_train['Comment']=df_train['Comment'].map(lambda x:parser(x))\n",
    "df_train['Comment']=df_train['Comment'].map(lambda x:badword_replacer(x))\n",
    "df_train['Comment_stemmed']=df_train['Comment'].map(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "\n",
    "df_test['Comment']=df_test['Comment'].map(lambda x:parser(x))\n",
    "df_test['Comment']=df_test['Comment'].map(lambda x:badword_replacer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_word_1  = [line.rstrip('\\n') for line in open('wordlist/google_bad_word.txt')]\n",
    "#bad_word_2  = [line.rstrip('\\n') for line in open('handcrafted_badword.txt')]\n",
    "bad_word= set(bad_word_1  + test_bad_word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dependency = pd.read_csv(PROCESSINGTEXT_DIR + '/dependency.csv')\n",
    "df_dependency = df_dependency.drop_duplicates()\n",
    "df_all = pd.merge(df_all, df_dependency, how='left', on='Comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['length']=df_all['Comment'].map(lambda x:len(x.split()))\n",
    "length = sparse.csr_matrix(df_all['length'].values).T\n",
    "\n",
    "bad_word_1  = [line.rstrip('\\n') for line in open('wordlist/google_bad_word.txt')]\n",
    "#bad_word_2  = [line.rstrip('\\n') for line in open('handcrafted_badword.txt')]\n",
    "bad_word= set(bad_word_1  + test_bad_word) \n",
    "\n",
    "df_all['bad word count']=df_all['Comment'].map(lambda x:sum([word.lower() in bad_word for word in x.split()]))\n",
    "df_all['bad word ratio']=df_all['bad word count']/df_all['length']\n",
    "\n",
    "bad_word_count = sparse.csr_matrix(df_all['bad word count'].values).T\n",
    "bad_word_ratio = sparse.csr_matrix(df_all['bad word ratio'].values).T\n",
    "\n",
    "strong_pos  = [line.rstrip('\\n') for line in open('wordlist/strong_pos.txt')]\n",
    "strong_neg  = [line.rstrip('\\n') for line in open('wordlist/strong_neg.txt')]\n",
    "weak_pos  = [line.rstrip('\\n') for line in open('wordlist/weak_pos.txt')]\n",
    "weak_neg  = [line.rstrip('\\n') for line in open('wordlist/weak_neg.txt')]\n",
    "\n",
    "df_all['strong pos count']=df_all['Comment'].map(lambda x:sum([word.lower() in strong_pos for word in x.split()]))\n",
    "df_all['strong pos ratio']=df_all['strong pos count']/df_all['length']\n",
    "df_all['strong neg count']=df_all['Comment'].map(lambda x:sum([word.lower() in strong_neg for word in x.split()]))\n",
    "df_all['strong neg ratio']=df_all['strong neg count']/df_all['length']\n",
    "df_all['weak pos count']=df_all['Comment'].map(lambda x:sum([word.lower() in weak_pos for word in x.split()]))\n",
    "df_all['weak neg count']=df_all['Comment'].map(lambda x:sum([word.lower() in weak_neg for word in x.split()]))\n",
    "df_all['sentence score']= np.exp((-3*df_all['bad word count'] + (-2)*df_all['strong neg count']+ (-1)*df_all['weak neg count']\\\n",
    "                        + 1*df_all['weak pos count'] + 2 * df_all['strong pos count'])/df_all['length'])\n",
    " \n",
    "sentence_score = sparse.csr_matrix(df_all['sentence score'].values).T    \n",
    "strong_pos_count = sparse.csr_matrix(df_all['strong pos count'].values).T\n",
    "strong_pos_ratio = sparse.csr_matrix(df_all['strong pos ratio'].values).T\n",
    "strong_neg_count = sparse.csr_matrix(df_all['strong neg count'].values).T\n",
    "strong_neg_ratio = sparse.csr_matrix(df_all['strong neg ratio'].values).T\n",
    "\n",
    "df_all['capital count']=df_all['Comment'].map(lambda x:sum([1 if word.isupper() else 0 for word in x.split()]))\n",
    "df_all['capital ratio']=df_all['capital count']/df_all['length']\n",
    "\n",
    "df_all['average word length']=df_all['Comment'].map(lambda x: np.mean([len(word) for word in x.split()]))\n",
    "df_all['max word length']=df_all['Comment'].map(lambda x: np.max([len(word) for word in x.split()]))\n",
    "\n",
    "df_all['email']=df_all['Comment'].map(lambda x: np.sum([1 if word=='_email_' else 0 for word in x.split()]))\n",
    "df_all['hashtag']=df_all['Comment'].map(lambda x: np.sum([1 if word=='_hashtag_' else 0 for word in x.split()]))\n",
    "df_all['url']=df_all['Comment'].map(lambda x: np.sum([1 if word=='_url_' else 0 for word in x.split()]))\n",
    "df_all['CR']=df_all['Comment'].map(lambda x: np.sum([1 if word=='_CR_' else 0 for word in x.split()]))\n",
    "\n",
    "def youare_count(x):\n",
    "    if re.search('you are',x.lower()):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_all['you are']=df_all['Comment'].map(lambda x: youare_count(x))\n",
    "\n",
    "capital_count = sparse.csr_matrix(df_all['capital count'].values).T\n",
    "capital_ratio = sparse.csr_matrix(df_all['capital ratio'].values).T\n",
    "average_word_length = sparse.csr_matrix(df_all['average word length'].values).T\n",
    "max_word_length = sparse.csr_matrix(df_all['max word length'].values).T\n",
    "email = sparse.csr_matrix(df_all['email'].values).T\n",
    "hashtag = sparse.csr_matrix(df_all['hashtag'].values).T\n",
    "url = sparse.csr_matrix(df_all['url'].values).T\n",
    "CR = sparse.csr_matrix(df_all['CR'].values).T\n",
    "you_are = sparse.csr_matrix(df_all['you are'].values).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tfidf/ count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "documents = sentence_reconnect(df_all['Comment_stemmed'].values)\n",
    "\n",
    "tfidf_char_ngram = TfidfVectorizer(ngram_range=(2, 5), min_df=3, analyzer='char') \n",
    "tfidf_char_ngram = tfidf_char_ngram.fit(documents)\n",
    "tfidf_char_ngram_all = tfidf_char_ngram.transform(df_all['Comment_stemmed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_word_ngram = TfidfVectorizer(ngram_range=(1, 5), min_df=3, analyzer='word') \n",
    "tfidf_word_ngram = tfidf_word_ngram.fit(documents)\n",
    "tfidf_word_ngram_all = tfidf_word_ngram.transform(df_all['Comment_stemmed'].values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tfidf_word_ngram_mean = tfidf_word_ngram_all.mean(axis=0)\n",
    "\n",
    "tfidf_word_ngram_similarity= [cosine_similarity(tfidf_word_ngram_mean, comment)[0][0] for comment in tfidf_word_ngram_all]\n",
    "df_all['tfidf word ngram similarity'] = tfidf_word_ngram_similarity\n",
    "tfidf_word_ngram_similarity = sparse.csr_matrix(tfidf_word_ngram_similarity).T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tfidf_word_ngram = TfidfVectorizer(ngram_range=(1, 6),min_df=2, analyzer='word') \n",
    "tfidf_word_ngram_2 = tfidf_word_ngram.fit(sentence_reconnect(df_all['Comment'].values))\n",
    "tfidf_word_ngram_all_2 = tfidf_word_ngram.transform(df_all['Comment'].values)\n",
    "\n",
    "count_word_ngram = CountVectorizer(ngram_range=(1, 4),min_df=3, analyzer='word') \n",
    "count_word_ngram_all = count_word_ngram .fit_transform(df_all['Comment_stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8829x24360 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 333200 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_word_ngram_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import lm\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def ngram_compute(x,n=3):\n",
    "    ngram_lst = []\n",
    "    for comment in x:\n",
    "        token = word_tokenize(comment)\n",
    "        ngrams_token=ngrams(token,n)\n",
    "        for i in ngrams_token:\n",
    "            ngram_lst.append(i)\n",
    "    return ngram_lst\n",
    "\n",
    "def language_model_prob(x):\n",
    "    prob_sum = 0\n",
    "    for i in x:\n",
    "        prob_sum += kneser_ney.prob(i)\n",
    "    return prob_sum\n",
    "\n",
    "def sentence_reconnect_lm(input):\n",
    "    reconnects= []\n",
    "    for text in input:\n",
    "        phrases = re.split(r'[;:\\.()\\n]', text)\n",
    "        phrases = [re.findall(r'[\\w%\\*&#]+', ph) for ph in phrases]\n",
    "        phrases = [ph for ph in phrases if ph]\n",
    "        for ph in phrases: \n",
    "            if ph:\n",
    "                reconnects = reconnects + ph\n",
    "    return reconnects \n",
    "\n",
    "def phrase(text):\n",
    "    reconnects= []\n",
    "    phrases = re.split(r'[;:\\.()\\n]', text)\n",
    "    phrases = [re.findall(r'[\\w%\\*&#]+', ph) for ph in phrases]\n",
    "    for ph in phrases: \n",
    "        if ph:\n",
    "            reconnects = reconnects + ph\n",
    "    return reconnects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zcakz\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "C:\\Users\\zcakz\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:17: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
     ]
    }
   ],
   "source": [
    "language = sentence_reconnect(df_all['Comment_stemmed'].values)\n",
    "\n",
    "trigram_lst = ngram_compute(language)\n",
    "freq_dist = nltk.FreqDist(trigram_lst)\n",
    "kneser_ney = nltk.KneserNeyProbDist(freq_dist)\n",
    "\n",
    "df_all['lm_prob_nltk']=df_all['Comment_stemmed'].map(lambda x: np.log(language_model_prob(ngrams(word_tokenize(x),3))+0.5))\n",
    "\n",
    "lm_prob_nltk = sparse.csr_matrix(df_all['lm_prob_nltk'].values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "language_2 = sentence_reconnect_lm(df_all['Comment_stemmed'].values)\n",
    "\n",
    "oov=lm.inject_OOVs(language_2)\n",
    "vocab = set(language_2)\n",
    "\n",
    "#KN_normal_1=lm.OOV_Modified_KneserNey(oov_normal,vocab,1) \n",
    "KN_2=lm.OOV_Modified_KneserNey(oov,vocab,2) \n",
    "KN_3=lm.OOV_Modified_KneserNey(oov,vocab,3,KN_2) \n",
    "KN_4=lm.OOV_Modified_KneserNey(oov,vocab,4,KN_3) \n",
    "KN_5=lm.OOV_Modified_KneserNey(oov,vocab,5,KN_4) \n",
    "KN_6=lm.OOV_Modified_KneserNey(oov,vocab,6,KN_5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['lm_prob_2']=df_all['Comment_stemmed'].map(lambda x: np.log(lm.perplexity(KN_2, phrase(x))+0.5))\n",
    "df_all['lm_prob_3']=df_all['Comment_stemmed'].map(lambda x: np.log(lm.perplexity(KN_3, phrase(x))+0.5))\n",
    "df_all['lm_prob_4']=df_all['Comment_stemmed'].map(lambda x: np.log(lm.perplexity(KN_4, phrase(x))+0.5))\n",
    "df_all['lm_prob_5']=df_all['Comment_stemmed'].map(lambda x: np.log(lm.perplexity(KN_5, phrase(x))+0.5))\n",
    "df_all['lm_prob_6']=df_all['Comment_stemmed'].map(lambda x: np.log(lm.perplexity(KN_6, phrase(x))+0.5))\n",
    "\n",
    "lm_prob_2 = sparse.csr_matrix(df_all['lm_prob_2'].values).T\n",
    "lm_prob_3 = sparse.csr_matrix(df_all['lm_prob_3'].values).T\n",
    "lm_prob_4 = sparse.csr_matrix(df_all['lm_prob_4'].values).T\n",
    "lm_prob_5 = sparse.csr_matrix(df_all['lm_prob_5'].values).T\n",
    "lm_prob_6 = sparse.csr_matrix(df_all['lm_prob_6'].values).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* syntatic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['syn obsub']= df_all['Dependency'].map(lambda x: obsub(x,bad_word))\n",
    "df_all['syn descriptive']= df_all['Dependency'].map(lambda x: descriptive(x,bad_word))\n",
    "df_all['syn possession']= df_all['Dependency'].map(lambda x: possession(x,bad_word))\n",
    "df_all['syn rhetorical']= df_all['Dependency'].map(lambda x: rhetorical(x,bad_word))\n",
    "df_all['syn close']= df_all['Dependency'].map(lambda x: close_phrase(x,bad_word))\n",
    "df_all['syn sum']=df_all['syn obsub'] + df_all['syn descriptive'] + df_all['syn possession'] + \\\n",
    "                  df_all['syn rhetorical'] + df_all['syn close']\n",
    "\n",
    "syn_obsub = sparse.csr_matrix(df_all['syn obsub'].values).T\n",
    "syn_descriptive = sparse.csr_matrix(df_all['syn descriptive'].values).T\n",
    "syn_possession = sparse.csr_matrix(df_all['syn possession'].values).T\n",
    "syn_rhetorical = sparse.csr_matrix(df_all['syn rhetorical'].values).T\n",
    "syn_close = sparse.csr_matrix(df_all['syn close'].values).T\n",
    "syn_sum = sparse.csr_matrix(df_all['syn sum'].values).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* features combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8829x100421 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3893772 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "features.append(tfidf_char_ngram_all)\n",
    "features.append(tfidf_word_ngram_all)\n",
    "#features.append(tfidf_word_ngram_all_2)\n",
    "#features.append(count_word_ngram_all)\n",
    "\n",
    "features.append(bad_word_ratio)\n",
    "features.append(strong_pos_ratio)\n",
    "features.append(strong_neg_ratio)\n",
    "features.append(strong_pos_count)\n",
    "features.append(strong_neg_count)\n",
    "features.append(sentence_score)\n",
    "features.append(length)\n",
    "\n",
    "features.append(capital_count) \n",
    "features.append(capital_ratio) \n",
    "features.append(average_word_length) \n",
    "features.append(max_word_length)\n",
    "features.append(email) \n",
    "features.append(hashtag) \n",
    "features.append(url)\n",
    "features.append(CR) \n",
    "features.append(you_are)\n",
    "\n",
    "features.append(syn_obsub)\n",
    "features.append(syn_descriptive)\n",
    "features.append(syn_possession) \n",
    "features.append(syn_sum)\n",
    "\n",
    "features = sparse.hstack(features).tocsr()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "ch2 = SelectKBest(chi2, k=50000)\n",
    "ch2.fit(features[:num_train], df_train['Insult'].values)\n",
    "features_filtered = ch2.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8829x50005 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2820448 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = sparse.hstack([features_filtered, lm_prob_2, lm_prob_3, lm_prob_4, lm_prob_5, lm_prob_6 ]).tocsr()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "val_list = np.random.choice(range(num_train), round(num_train/10))\n",
    "train_list = list(set(range(num_train)).difference(set(val_list))) \n",
    "\n",
    "X_train = features[:num_train][train_list]\n",
    "X_val = features[:num_train][val_list]\n",
    "X_test = features[num_train:]\n",
    "\n",
    "y_train = df_train['Insult'].values[train_list]\n",
    "y_val =  df_train['Insult'].values[val_list]\n",
    "y_test = df_test['Insult'].values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_train = features[:num_train]\n",
    "X_test = features[num_train:]\n",
    "\n",
    "y_train = df_train['Insult']\n",
    "y_test = df_test['Insult'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model training time:', 0.1, 'minutes\\n')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "t_1 = time.time()\n",
    "\n",
    "clf = LogisticRegression(tol=1e-8, penalty='l2', C=0.5, class_weight = 'balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "val_pred_prob = clf.predict_proba(X_val)[:,1]\n",
    "val_pred = clf.predict(X_val)\n",
    "test_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "'model training time:',round((time.time()-t_1)/60,1) ,'minutes\\n'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "t_1 = time.time()\n",
    "\n",
    "clf = LogisticRegression(tol=1e-9, penalty='l2', C=5, class_weight = 'balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "test_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "'model training time:',round((time.time()-t_1)/60,1) ,'minutes\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74242424242424254, 0.92377188029361945)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "f1_score(y_val, val_pred),roc_auc_score(y_val,val_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.73756097560975609, 0.82767891363298873)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "f1_score(y_test, test_pred),roc_auc_score(y_test,test_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('feature_pred_val_prob', val_pred_prob)\n",
    "np.save('feature_pred_val', val_pred)\n",
    "#np.save('feature_pred_test_prob', test_pred_prob)\n",
    "#np.save('feature_pred_test', test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix_dict(matrix,rotation=45, outside_label=\"\"):\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(0)\n",
    "    plt.xticks(tick_marks, [0,1], rotation=rotation)\n",
    "    plt.yticks(tick_marks, [0,1])\n",
    "    \n",
    "cm=confusion_matrix(y_test, test_pred, labels=None, sample_weight=None)\n",
    "print(cm)\n",
    "plot_confusion_matrix_dict(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('false posotive: ',predict_analysis(y_test, y_pred, y_pred_prob, 'fp', df_test)[50])\n",
    "print('false posotive: ',predict_analysis(y_test, y_pred, y_pred_prob, 'fp', df_test)[3])\n",
    "print('false negative: ',predict_analysis(y_test, y_pred, y_pred_prob, 'fn', df_test)[150])\n",
    "print('false negative: ',predict_analysis(y_test, y_pred, y_pred_prob, 'fn', df_test)[2])\n",
    "print('true posotive: ',predict_analysis(y_test, y_pred, y_pred_prob, 'tp', df_test)[50])\n",
    "print('true negative: ',predict_analysis(y_test, y_pred, y_pred_prob, 'tn', df_test)[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
